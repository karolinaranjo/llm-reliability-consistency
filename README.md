# LLM Reliability & Consistency 
Foundational Papers

![Reliability](https://img.shields.io/badge/-Reliability-orange)
![Consistency](https://img.shields.io/badge/-Consistency-blue)
![Model](https://img.shields.io/badge/Model-LLMs-green)
![Data](https://img.shields.io/badge/Data-Benchmarks-purple)
![Type](https://img.shields.io/badge/Type-Literature%20Review-lightblue)

## Reliability Papers
| Paper | Tags | Venue/Source | Year | Code | Description |
|---|---|---|---|---|---|
| [TrustLLM: Trustworthiness in Large Language Models](https://arxiv.org/pdf/2401.05561) | `truthfulness` `safety` `fairness` `robustness` `privacy` `machine ethics`| ICML | 2024 | [Official](https://github.com/HowieHwong/TrustLLM) \| [HuggingFace](https://huggingface.co/papers/2401.05561) | TrustLLM is a comprehensive framework for studying trustworthiness of large language models, which includes principles, surveys, and benchmarks.|

## Consistency Papers





---
**Curated by:** [Dane Williamson](https://github.com/dwil2444) & [Karolina Naranjo](https://github.com/karolinaranjo)

**Lab:** [UVA Information and Language Processing Lab](https://github.com/UVa-NLP)












